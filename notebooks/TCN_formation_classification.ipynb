{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version  2.6.0\n",
      "\n",
      "--- Load, inspect and transform data ---\n",
      "\n",
      "Number of columns in the dataframe: 26\n",
      "Number of rows in the dataframe: 1170511\n",
      "\n",
      "First 20 rows of the dataframe:\n",
      "\n",
      "    Unnamed: 0  Unnamed: 0.1  DEPTH_MD    X_LOC     Y_LOC  Z_LOC  CALI   RSHA  \\\n",
      "0            0             0     494.5 437642.0 6470972.5 -469.5  19.5 -999.0   \n",
      "1            1             1     494.7 437642.0 6470972.5 -469.7  19.5 -999.0   \n",
      "2            2             2     494.8 437642.0 6470972.5 -469.8  19.5 -999.0   \n",
      "3            3             3     495.0 437642.0 6470972.5 -470.0  19.5 -999.0   \n",
      "4            4             4     495.1 437642.0 6470972.5 -470.1  19.5 -999.0   \n",
      "5            5             5     495.3 437642.0 6470972.5 -470.3  19.5 -999.0   \n",
      "6            6             6     495.4 437642.0 6470972.5 -470.4  19.5 -999.0   \n",
      "7            7             7     495.6 437642.0 6470972.5 -470.6  19.5 -999.0   \n",
      "8            8             8     495.7 437642.0 6470972.5 -470.7  19.5 -999.0   \n",
      "9            9             9     495.9 437642.0 6470972.5 -470.9  19.5 -999.0   \n",
      "10          10            10     496.0 437642.0 6470972.5 -471.0  19.5 -999.0   \n",
      "11          11            11     496.2 437642.0 6470972.5 -471.2  19.5 -999.0   \n",
      "12          12            12     496.4 437642.0 6470972.5 -471.3  19.5 -999.0   \n",
      "13          13            13     496.5 437642.0 6470972.5 -471.5  19.5 -999.0   \n",
      "14          14            14     496.7 437642.0 6470972.5 -471.6  19.5 -999.0   \n",
      "15          15            15     496.8 437642.0 6470972.5 -471.8  19.5 -999.0   \n",
      "16          16            16     497.0 437642.0 6470972.5 -471.9  19.5 -999.0   \n",
      "17          17            17     497.1 437642.0 6470972.5 -472.1  19.5 -999.0   \n",
      "18          18            18     497.3 437642.0 6470972.5 -472.2  19.5 -999.0   \n",
      "19          19            19     497.4 437642.0 6470972.5 -472.4  19.5 -999.0   \n",
      "\n",
      "    RMED  RDEP  ...     BS  ROP   DCAL  DRHO  MUDWEIGHT   RMIC  GROUP_encoded  \\\n",
      "0    1.6   1.8  ... -999.0 34.6 -999.0  -0.6     -999.0 -999.0              6   \n",
      "1    1.6   1.8  ... -999.0 34.6 -999.0  -0.6     -999.0 -999.0              6   \n",
      "2    1.6   1.8  ... -999.0 34.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "3    1.6   1.8  ... -999.0 40.0 -999.0  -0.6     -999.0 -999.0              6   \n",
      "4    1.6   1.8  ... -999.0 57.5 -999.0  -0.6     -999.0 -999.0              6   \n",
      "5    1.6   1.8  ... -999.0 75.3 -999.0  -0.6     -999.0 -999.0              6   \n",
      "6    1.6   1.8  ... -999.0 76.2 -999.0  -0.6     -999.0 -999.0              6   \n",
      "7    1.6   1.8  ... -999.0 76.2 -999.0  -0.6     -999.0 -999.0              6   \n",
      "8    1.6   1.8  ... -999.0 75.9 -999.0  -0.6     -999.0 -999.0              6   \n",
      "9    1.6   1.8  ... -999.0 68.1 -999.0  -0.6     -999.0 -999.0              6   \n",
      "10   1.6   1.8  ... -999.0 47.2 -999.0  -0.6     -999.0 -999.0              6   \n",
      "11   1.6   1.8  ... -999.0 46.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "12   1.6   1.8  ... -999.0 46.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "13   1.6   1.8  ... -999.0 46.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "14   1.6   1.8  ... -999.0 46.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "15   1.6   1.8  ... -999.0 46.6 -999.0  -0.6     -999.0 -999.0              6   \n",
      "16   1.6   1.8  ... -999.0 46.3 -999.0  -0.6     -999.0 -999.0              6   \n",
      "17   1.6   1.8  ... -999.0 46.1 -999.0  -0.6     -999.0 -999.0              6   \n",
      "18   1.6   1.8  ... -999.0 45.8 -999.0  -0.6     -999.0 -999.0              6   \n",
      "19   1.6   1.8  ... -999.0 45.6 -999.0  -0.6     -999.0 -999.0              6   \n",
      "\n",
      "    FORMATION_encoded  WELL_encoded  LITHOLOGY  \n",
      "0                  -1             0          2  \n",
      "1                  -1             0          2  \n",
      "2                  -1             0          2  \n",
      "3                  -1             0          2  \n",
      "4                  -1             0          2  \n",
      "5                  -1             0          2  \n",
      "6                  -1             0          2  \n",
      "7                  -1             0          2  \n",
      "8                  -1             0          2  \n",
      "9                  -1             0          2  \n",
      "10                 -1             0          2  \n",
      "11                 -1             0          2  \n",
      "12                 -1             0          2  \n",
      "13                 -1             0          2  \n",
      "14                 -1             0          2  \n",
      "15                 -1             0          2  \n",
      "16                 -1             0          2  \n",
      "17                 -1             0          2  \n",
      "18                 -1             0          2  \n",
      "19                 -1             0          2  \n",
      "\n",
      "[20 rows x 26 columns]\n",
      "\n",
      "Description of dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.figure.Figure at 0x155af6e7400>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<matplotlib.figure.Figure at 0x155af7f3160>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reshape the data into segments ---\n",
      "\n",
      "\n",
      "--- Reshape data to be accepted by Keras ---\n",
      "\n",
      "x_train shape:  (13645, 160, 23)\n",
      "13645 training samples\n",
      "y_train shape:  (13645,)\n",
      "[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "x_train shape: (13645, 3680)\n",
      "input_shape: 3680\n",
      "New y_train shape:  (13645, 15)\n",
      "\n",
      "--- Create neural network model ---\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 160, 23)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 151, 100)          23100     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 142, 100)          100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 47, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 38, 160)           160160    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 29, 160)           256160    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                2415      \n",
      "=================================================================\n",
      "Total params: 541,935\n",
      "Trainable params: 541,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "--- Fit the model ---\n",
      "\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 14s 622ms/step - loss: 2.2544 - accuracy: 0.2321 - val_loss: 2.1448 - val_accuracy: 0.1202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 13s 581ms/step - loss: 2.0583 - accuracy: 0.2653 - val_loss: 2.1199 - val_accuracy: 0.1136\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 1.9156 - accuracy: 0.3119 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d42d1f34b3c0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0madd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mConv1D\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mActivation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFlatten\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformation_1d_cnn_force_data\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfeature_normalize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_segments_and_labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\workspace\\scientificProject\\stratigraphic_classfication_correlation\\models\\formation_1d_cnn_force_data.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    350\u001B[0m                       \u001B[1;31m# 在训练集的数据中将数据以8：2的比例分开（2/10=0.2），\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    351\u001B[0m                       \u001B[1;31m# 8的进行训练（train），2的进行核对（validation ）\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 352\u001B[1;33m                       verbose=1)\n\u001B[0m\u001B[0;32m    353\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[1;31m# %%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1224\u001B[0m               \u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1225\u001B[0m               \u001B[0mreturn_dict\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1226\u001B[1;33m               _use_cached_eval_dataset=True)\n\u001B[0m\u001B[0;32m   1227\u001B[0m           \u001B[0mval_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'val_'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mval\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mval_logs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1228\u001B[0m           \u001B[0mepoch_logs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_logs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'test'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1501\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 885\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    886\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    922\u001B[0m       \u001B[1;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    923\u001B[0m       \u001B[1;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 924\u001B[1;33m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    925\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_created_variables\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    926\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3038\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m   3039\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m-> 3040\u001B[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   3041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3042\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1962\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1963\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1964\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1965\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 596\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    597\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\welllogAI\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 60\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.integration_test.preprocessing_test_utils import preprocessing\n",
    "from keras.models import Model\n",
    "from keras.layers import add, Input, Conv1D, Activation, Flatten, Dense\n",
    "\n",
    "\n",
    "# 载入数据\n",
    "\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    TIME_PERIODS = 160\n",
    "    STEP_DISTANCE = 80\n",
    "    features = ['DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC',\n",
    "                'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC',\n",
    "                'SP', 'BS', 'ROP', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC', 'FORMATION_encoded',\n",
    "                'WELL_encoded', 'LITHOLOGY']\n",
    "    for f in features:\n",
    "        df = df.round({f: 3})  # 保留3位小数点\n",
    "        df[f] = feature_normalize(df[f])\n",
    "\n",
    "    df_test = df[df['WELL_encoded'] <= 10]\n",
    "    df_validation = df[df['WELL_encoded'] in range(11, 21)]\n",
    "    df_train = df[df['WELL_encoded'] > 20]\n",
    "\n",
    "    LABEL = \"GroupEncoded\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # 标准化标签，将标签值统一转换成range(标签值个数-1)范围内\n",
    "    df[LABEL] = le.fit_transform(df[\"GROUP_encoded\"].values.ravel())\n",
    "\n",
    "    x_train, y_train = create_segments_and_labels(df_train,\n",
    "                                                  TIME_PERIODS,\n",
    "                                                  STEP_DISTANCE,\n",
    "                                                  LABEL,\n",
    "                                                  features)\n",
    "\n",
    "    x_valid, y_valid = create_segments_and_labels(df_validation,\n",
    "                                                  TIME_PERIODS,\n",
    "                                                  STEP_DISTANCE,\n",
    "                                                  LABEL,\n",
    "                                                  features)\n",
    "\n",
    "    x_test, y_test = create_segments_and_labels(df_test,\n",
    "                                                TIME_PERIODS,\n",
    "                                                STEP_DISTANCE,\n",
    "                                                LABEL,\n",
    "                                                features)\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "\n",
    "\n",
    "# 残差块\n",
    "def ResBlock(x, filters, kernel_size, dilation_rate):\n",
    "    r = Conv1D(filters, kernel_size, padding='same', dilation_rate=dilation_rate, activation='relu')(x)  # 第一卷积\n",
    "    r = Conv1D(filters, kernel_size, padding='same', dilation_rate=dilation_rate)(r)  # 第二卷积\n",
    "    if x.shape[-1] == filters:\n",
    "        shortcut = x\n",
    "    else:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same')(x)  # shortcut（捷径）\n",
    "    o = add([r, shortcut])\n",
    "    o = Activation('relu')(o)  # 激活函数\n",
    "    return o\n",
    "\n",
    "\n",
    "# 序列模型\n",
    "def TCN(train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "    inputs = Input(shape=(28, 28))\n",
    "    x = ResBlock(inputs, filters=32, kernel_size=3, dilation_rate=1)\n",
    "    x = ResBlock(x, filters=32, kernel_size=3, dilation_rate=2)\n",
    "    x = ResBlock(x, filters=16, kernel_size=3, dilation_rate=4)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input=inputs, output=x)\n",
    "    # 查看网络结构\n",
    "    model.summary()\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # 训练模型\n",
    "    model.fit(train_x, train_y, batch_size=500, nb_epoch=30, verbose=2, validation_data=(valid_x, valid_y))\n",
    "    # 评估模型\n",
    "    pre = model.evaluate(test_x, test_y, batch_size=500, verbose=2)\n",
    "    print('test_loss:', pre[0], '- test_acc:', pre[1])\n",
    "\n",
    "\n",
    "train_x, train_y, valid_x, valid_y, test_x, test_y = read_data(r'D:\\workspace\\scientificProject\\stratigraphic_classfication_correlation\\data\\force-train.csv')\n",
    "TCN(train_x, train_y, valid_x, valid_y, test_x, test_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}